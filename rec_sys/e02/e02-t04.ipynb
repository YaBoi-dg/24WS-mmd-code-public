{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a script to perform SGD on a polynomial with 3 variables x,y,z i.e $\\sum a_{i,j,k}x^iy^jz^k$. The polynomial should have maximum degree $N_x$ for x, $N_y$ for y, and $N_z$ for z."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Disregarding t, what is the maximum number of coeffcients needed to fully specify $P(x, y, z)$ for given $N_x, N_y, N_z$?\n",
    "\n",
    "The number of terms in $P(x,y,z)$ can be calculated as the product of possibilities for each variable that is $(N_x+1)(N_y+1)(N_z+1)$.\n",
    "In JAX, a data structure for storing these coefficients is a 3D array, where each dimension corresponds to the power of $x,y,z$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. c. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_random(Nx,Ny,Nz,t):\n",
    "    coefficients = jnp.zeros((Nx + 1, Ny + 1, Nz + 1))\n",
    "    terms = set()\n",
    "\n",
    "    while len(terms) < t:\n",
    "        i = random.randint(0,Nx)\n",
    "        j = random.randint(0,Ny)\n",
    "        k = random.randint(0,Nz)\n",
    "        if (i, j, k) not in terms:\n",
    "            terms.add((i, j, k))\n",
    "            \n",
    "            coefficients = coefficients.at[i, j, k].set(random.uniform(-5, 5))\n",
    "        return coefficients\n",
    "    \n",
    "\n",
    "\n",
    "def eval_poly(coefficients, x,y,z):\n",
    "    Nx,Ny,Nz = coefficients.shape\n",
    "    result = 0\n",
    "    for i in range(Nx):\n",
    "        for j in range(Ny):\n",
    "            for k in range(Nz):\n",
    "                result += coefficients[i, j, k] * (x ** i) * (y ** j) * (z ** k)\n",
    "    return result\n",
    "\n",
    "def gen_train_data(coefficients, N, noise_frac=0.1, rnd_seed=42):\n",
    "    rng = jax.random.PRNGKey(rnd_seed)\n",
    "    data = []\n",
    "\n",
    "    for _ in range(N):\n",
    "        x = random.uniform(-10,10)\n",
    "        y = random.uniform(-10,10)\n",
    "        z = random.uniform(-10,10)\n",
    "        true_value = eval_poly(coefficients,x,y,z)\n",
    "        noise = noise_frac * true_value * jax.random.normal(rng, ())\n",
    "        noisy_value = true_value + noise\n",
    "        data.append((x, y, z, noisy_value))\n",
    "\n",
    "    return jnp.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss funstion and its gradient\n",
    "\n",
    "def loss(params, data):\n",
    "    errors = [(eval_poly(params, x, y, z) - target) ** 2 for x, y, z, target in data]\n",
    "    return jnp.log(jnp.sum(jnp.array(errors)))\n",
    "\n",
    "grad_loss = jax.grad(loss)\n",
    "\n",
    "def sgd_reconstruct(training_data, Nx, Ny, Nz, t, num_epochs=500, learning_rate=0.001):\n",
    "    # Initialize random coefficients\n",
    "    #params = jnp.zeros((Nx + 1, Ny + 1, Nz + 1))\n",
    "    coefficients = gen_random(Nx, Ny, Nz, t)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i in range(len(training_data)):\n",
    "            batch = training_data[i:i+1]\n",
    "            grad = grad_loss(coefficients, batch)\n",
    "            coefficients = coefficients - learning_rate * grad\n",
    "        if epoch % 2 == 0:\n",
    "            print(f\"Epoch {epoch}: Loss={loss(coefficients, training_data)}\")\n",
    "    return coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reconstructing coefficients for Polynomial 1\n",
      "Epoch 0: Loss=55.798526763916016\n",
      "Epoch 2: Loss=55.797176361083984\n",
      "Epoch 4: Loss=55.79582595825195\n",
      "Epoch 6: Loss=55.794471740722656\n",
      "Epoch 8: Loss=55.793113708496094\n",
      "Epoch 10: Loss=55.791748046875\n",
      "Epoch 12: Loss=55.790382385253906\n",
      "Epoch 14: Loss=55.78900909423828\n",
      "Epoch 16: Loss=55.78763198852539\n",
      "Epoch 18: Loss=55.7862434387207\n",
      "Epoch 20: Loss=55.784828186035156\n",
      "Epoch 22: Loss=55.78434371948242\n",
      "Epoch 24: Loss=55.78298568725586\n",
      "Epoch 26: Loss=55.78162384033203\n",
      "Epoch 28: Loss=55.7802619934082\n",
      "Epoch 30: Loss=55.778900146484375\n",
      "Epoch 32: Loss=55.777530670166016\n",
      "Epoch 34: Loss=55.77616500854492\n",
      "Epoch 36: Loss=55.7747917175293\n",
      "Epoch 38: Loss=55.77342224121094\n",
      "Epoch 40: Loss=55.77204513549805\n",
      "Epoch 42: Loss=55.770668029785156\n",
      "Epoch 44: Loss=55.769290924072266\n",
      "Epoch 46: Loss=55.76791000366211\n",
      "Epoch 48: Loss=55.76652526855469\n",
      "Epoch 50: Loss=55.765140533447266\n",
      "Epoch 52: Loss=55.763755798339844\n",
      "Epoch 54: Loss=55.762367248535156\n",
      "Epoch 56: Loss=55.7609748840332\n",
      "Epoch 58: Loss=55.759578704833984\n",
      "Epoch 60: Loss=55.758182525634766\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret 'Array(-1.1003532, dtype=float32)' as a data type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Run SGD on each polynomial's training data\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mReconstructing coefficients for Polynomial 1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m reconstructed_poly1 \u001b[38;5;241m=\u001b[39m \u001b[43msgd_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_data1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNy1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNz1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mReconstructing coefficients for Polynomial 2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m reconstructed_poly2 \u001b[38;5;241m=\u001b[39m sgd_reconstruct(training_data2, Nx2, Ny2, Nz2, t2)\n",
      "Cell \u001b[0;32mIn[26], line 16\u001b[0m, in \u001b[0;36msgd_reconstruct\u001b[0;34m(training_data, Nx, Ny, Nz, t, num_epochs, learning_rate)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(training_data)):\n\u001b[1;32m     15\u001b[0m     batch \u001b[38;5;241m=\u001b[39m training_data[i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 16\u001b[0m     grad \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoefficients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     coefficients \u001b[38;5;241m=\u001b[39m coefficients \u001b[38;5;241m-\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m grad\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "    \u001b[0;31m[... skipping hidden 10 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[26], line 4\u001b[0m, in \u001b[0;36mloss\u001b[0;34m(params, data)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(params, data):\n\u001b[0;32m----> 4\u001b[0m     errors \u001b[38;5;241m=\u001b[39m [(\u001b[43meval_poly\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m target) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x, y, z, target \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m jnp\u001b[38;5;241m.\u001b[39mlog(jnp\u001b[38;5;241m.\u001b[39msum(jnp\u001b[38;5;241m.\u001b[39marray(errors)))\n",
      "Cell \u001b[0;32mIn[10], line 23\u001b[0m, in \u001b[0;36meval_poly\u001b[0;34m(coefficients, x, y, z)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(Ny):\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(Nz):\n\u001b[0;32m---> 23\u001b[0m             \u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcoefficients\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Desktop/24WS-mmd-code-public-main 3/rec_sys/.venv/lib/python3.12/site-packages/jax/_src/numpy/array_methods.py:1050\u001b[0m, in \u001b[0;36m_forward_operator_to_aval.<locals>.op\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mop\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m-> 1050\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/24WS-mmd-code-public-main 3/rec_sys/.venv/lib/python3.12/site-packages/jax/_src/numpy/array_methods.py:569\u001b[0m, in \u001b[0;36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeferring_binary_op\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m--> 569\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m__jax_array__\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    570\u001b[0m     other \u001b[38;5;241m=\u001b[39m other\u001b[38;5;241m.\u001b[39m__jax_array__()\n\u001b[1;32m    571\u001b[0m   args \u001b[38;5;241m=\u001b[39m (other, \u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m swap \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mself\u001b[39m, other)\n",
      "    \u001b[0;31m[... skipping hidden 5 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/24WS-mmd-code-public-main 3/rec_sys/.venv/lib/python3.12/site-packages/jax/_src/core.py:1859\u001b[0m, in \u001b[0;36mConcreteArray.__init__\u001b[0;34m(self, dtype, val, weak_type)\u001b[0m\n\u001b[1;32m   1857\u001b[0m dtypes\u001b[38;5;241m.\u001b[39mcheck_valid_dtype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m   1858\u001b[0m \u001b[38;5;66;03m# Note: canonicalized self.dtype doesn't necessarily match self.val\u001b[39;00m\n\u001b[0;32m-> 1859\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mcanonicalize_dtype(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m), (val, dtype)\n\u001b[1;32m   1860\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval \u001b[38;5;241m=\u001b[39m val\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot interpret 'Array(-1.1003532, dtype=float32)' as a data type"
     ]
    }
   ],
   "source": [
    "#Testing\n",
    "\n",
    "Nx1, Ny1, Nz1, t1 = 2, 4, 6, 12\n",
    "Nx2, Ny2, Nz2, t2 = 3, 1, 2, 5\n",
    "N_data = 10  # Training data size\n",
    "noise_frac = 0.1\n",
    "\n",
    "secret_poly1 = gen_random(Nx1, Ny1, Nz1, t1)\n",
    "training_data1 = gen_train_data(secret_poly1, N_data, noise_frac)\n",
    "\n",
    "secret_poly2 = gen_random(Nx2, Ny2, Nz2, t2)\n",
    "training_data2 = gen_train_data(secret_poly2, N_data, noise_frac)\n",
    "\n",
    "# Run SGD on each polynomial's training data\n",
    "print(\"\\nReconstructing coefficients for Polynomial 1\")\n",
    "reconstructed_poly1 = sgd_reconstruct(training_data1, Nx1, Ny1, Nz1, t1)\n",
    "\n",
    "print(\"\\nReconstructing coefficients for Polynomial 2\")\n",
    "reconstructed_poly2 = sgd_reconstruct(training_data2, Nx2, Ny2, Nz2, t2)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
